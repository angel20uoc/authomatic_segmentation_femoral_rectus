{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "001c2807-18e3-4757-80cb-5404839ae33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e28a450-977b-47b1-8272-9d1ad14b59b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Memoria GPU configurada correctamente\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"✓ Memoria GPU configurada correctamente\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c45d32ee-69b1-4915-9e99-a8b2a572bac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando 10490 imágenes de Albacete...\n",
      "Procesando 10016 imágenes de Barcelona...\n",
      "Procesando 5906 imágenes de Caceres...\n",
      "Procesando 1161 imágenes de Getafe...\n",
      "Procesando 3566 imágenes de Goya_Madrid...\n",
      "Procesando 1714 imágenes de Guadalajara...\n",
      "Procesando 7286 imágenes de La_Paz...\n",
      "Procesando 8713 imágenes de Navarra...\n",
      "Procesando 6325 imágenes de Salamanca...\n",
      "✔ Preprocesado completado.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 1) DETECTAR AUTOMÁTICAMENTE LA ZONA ÚTIL (HAZ DE ULTRASONIDO)\n",
    "# ============================================================\n",
    "\n",
    "def detect_ultrasound_field(img, thresh=12):\n",
    "    \"\"\"\n",
    "    Detecta automáticamente el área útil del ultrasonido.\n",
    "    Funciona tanto para imágenes rectangulares como trapezoidales.\n",
    "    \"\"\"\n",
    "    gray = img.copy()\n",
    "\n",
    "    # 1) Binarización suave (ignora bordes negros y texto)\n",
    "    _, bw = cv2.threshold(gray, thresh, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # 2) Abrir para eliminar ruido pequeño\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    clean = cv2.morphologyEx(bw, cv2.MORPH_OPEN, kernel)\n",
    "\n",
    "    # 3) Elegir el contorno MÁS GRANDE (suele ser el campo acústico)\n",
    "    contours, _ = cv2.findContours(clean, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return img  # fallback\n",
    "\n",
    "    c = max(contours, key=cv2.contourArea)\n",
    "    x, y, w, h = cv2.boundingRect(c)\n",
    "\n",
    "    return img[y:y+h, x:x+w]\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 2) ELIMINAR SOLO PARTES SUPERIORES QUE NO SON TEJIDO\n",
    "# ============================================================\n",
    "\n",
    "def remove_headers_safely(img, max_cut_ratio=0.35):\n",
    "    \"\"\"\n",
    "    Detecta si arriba hay una zona negra grande y la elimina sin afectar tejido.\n",
    "    \"\"\"\n",
    "    h, w = img.shape\n",
    "\n",
    "    # Perfil vertical de intensidad\n",
    "    col_mean = img.mean(axis=1)\n",
    "\n",
    "    # Normalizar para evaluar contraste\n",
    "    col_norm = (col_mean - col_mean.min()) / (col_mean.max() - col_mean.min() + 1e-6)\n",
    "\n",
    "    # Buscamos primera zona brillante (tejido real)\n",
    "    threshold = 0.08\n",
    "    tissue_rows = np.where(col_norm > threshold)[0]\n",
    "\n",
    "    if len(tissue_rows) == 0:\n",
    "        return img\n",
    "\n",
    "    first_row = tissue_rows[0]\n",
    "\n",
    "    # limitar recorte\n",
    "    limit = int(h * max_cut_ratio)\n",
    "    if first_row < limit:\n",
    "        return img[first_row:, :]\n",
    "    else:\n",
    "        return img\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 3) NORMALIZACIÓN\n",
    "# ============================================================\n",
    "\n",
    "def enhance_clahe(img):\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    return clahe.apply(img)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 4) REDIMENSIONAR CON PADDING\n",
    "# ============================================================\n",
    "\n",
    "def resize_with_padding(img, target=(384,384)):\n",
    "    h, w = img.shape\n",
    "    th, tw = target\n",
    "\n",
    "    scale = min(th/h, tw/w)\n",
    "    nh, nw = int(h*scale), int(w*scale)\n",
    "    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    canvas = np.zeros((th, tw), dtype=np.uint8)\n",
    "    y0 = (th - nh)//2\n",
    "    x0 = (tw - nw)//2\n",
    "    canvas[y0:y0+nh, x0:x0+nw] = resized\n",
    "\n",
    "    return canvas\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 5) PIPELINE COMPLETO DE PREPROCESADO ROBUSTO\n",
    "# ============================================================\n",
    "\n",
    "def preprocess_image(input_path, output_path):\n",
    "    img = cv2.imread(input_path, cv2.IMREAD_GRAYSCALE)\n",
    "    if img is None:\n",
    "        print(\"ERROR leyendo:\", input_path)\n",
    "        return\n",
    "\n",
    "    # 1) Detectar campo acústico\n",
    "    img = detect_ultrasound_field(img)\n",
    "\n",
    "    # 2) Quitar headers sin tocar tejido\n",
    "    img = remove_headers_safely(img)\n",
    "\n",
    "    # 3) Mejorar contraste CLAHE\n",
    "    img = enhance_clahe(img)\n",
    "\n",
    "    # 4) Redimensionar con padding\n",
    "    img = resize_with_padding(img, target=(384,384))\n",
    "\n",
    "    # 5) Guardar\n",
    "    img_to_save = img.astype(np.uint8)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    cv2.imwrite(output_path, img_to_save, [int(cv2.IMWRITE_JPEG_QUALITY), 95])\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# 6) PROCESAMIENTO MASIVO\n",
    "# ============================================================\n",
    "\n",
    "base_in = r\"../data/imgs\"\n",
    "base_out = r\"../data/processed_2\"\n",
    "\n",
    "centers = [\n",
    "    \"Albacete\",\"Barcelona\",\"Caceres\",\"Getafe\",\n",
    "    \"Goya_Madrid\",\"Guadalajara\",\"La_Paz\",\"Navarra\",\"Salamanca\"\n",
    "]\n",
    "\n",
    "for c in centers:\n",
    "    in_folder = os.path.join(base_in, c)\n",
    "    out_folder = os.path.join(base_out, c)\n",
    "\n",
    "    files = glob(os.path.join(in_folder, \"*.jpeg\"))\n",
    "\n",
    "    print(f\"Procesando {len(files)} imágenes de {c}...\")\n",
    "\n",
    "    for f in files:\n",
    "        fname = os.path.basename(f)\n",
    "        outp = os.path.join(out_folder, fname)\n",
    "        preprocess_image(f, outp)\n",
    "\n",
    "print(\"✔ Preprocesado completado.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
